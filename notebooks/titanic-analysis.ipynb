{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Titanic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Defining the Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sinking of the Titanic is one of the most infamous shipwrecks in history.\n",
    "\n",
    "On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n",
    "While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n",
    "\n",
    "In this challenge, we will build a predictive model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc).\n",
    "\n",
    "In terms of structure, the analysis performed will follow a classical data science framework, which consists in the following points:\n",
    "\n",
    "\n",
    "1. Defining the Problem: summarizing what is the challenge we are facing and which we want to give a solution to.\n",
    "\n",
    "2. Importing Libraries and Gathering the Data\n",
    "\n",
    "3. Data Cleansing: also known as data wrangling, consists in turning \"raw\" (or uncleansed) data to clean data, by identifying and treating outliers, missing values, data formats, etc.\n",
    "\n",
    "4. Exploratory and Statistical Analysis: descriptive and graphical statistical analysis will be performed in order to look at patterns, correlations and features profiling. This is a required step so that the correct hypothesis is selected to further deploy a data model.\n",
    "\n",
    "5. Modelling Data: consist in implementing and training different algorithms to predict the required outcomes.\n",
    "\n",
    "6. Fine-tuning the Model(s): in this section, the models deployed earlier are tested using a testing dataset. It's the place, for instance, to determine if our model is overfitted or underfitted.\n",
    "\n",
    "7. Validation and Final Conclusions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Importing Libraries & Gathering the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are given two different datasets: train & test. The train dataset, the one to be used to perform the different data analysis and train the model, is given at: https://www.kaggle.com/competitions/titanic/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries and modules\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required data: Train & test data\n",
    "df_train=pd.read_csv(\"/Users/joelbullich/Desktop/Titanic Challenge/data/train.csv\")\n",
    "df_test=pd.read_csv(\"/Users/joelbullich/Desktop/Titanic Challenge/data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying the Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "______________________________\n",
      "\n",
      "TEST DATA\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.1+ KB\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAIN DATA\\n\")\n",
    "df_train.info()\n",
    "print(\"_\"*30)\n",
    "print(\"\\nTEST DATA\\n\")\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables contained in our dataset are:\n",
    "\n",
    "*Dependent Variable*\n",
    "\n",
    "- **Survived**: binary dependent variable with 2 different outcomes: \"1\" for those passengers that survived and \"0\" for those who did not\n",
    "All other variables are potential predictor or independent variables. It's important to note, more predictor variables do not make a better model, but the right variables\n",
    "\n",
    "*Independent Variables*\n",
    "\n",
    "- **PassengerID** | **Ticket ID**:  are considered unique identifiers that should not have any impact to the dependent variable (therefore, to be excluded)\n",
    "\n",
    "- **Pclass**: it is an ordinal number that describes the ticket class, which represents the socio-economic status of each passenger. Values vary between 1=Upper Class, 2=Middle Class\" and 3=\"Lower Class\"\n",
    "\n",
    "- **Name**: represents the passenger name\n",
    "\n",
    "- **Sex** | **Embarked**: to be converted to dummy variables\n",
    "\n",
    "- **Age** | **Fare**:  continuous quantitative variable datatypes.\n",
    "\n",
    "- **SibSp**: represents number of related siblings/spouse aboard\n",
    "\n",
    "- **Parch**: represents number of related parents/children aboard. \n",
    "This one and SibSp could be used to create an extra column to identify if a passenger travels alone or not.\n",
    "\n",
    "- **Cabin**: variable that identifies which cabin was assigned to each passenger/ticket. Lots of Null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Glynn, Miss. Mary Agatha</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>335677</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>276</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Andrews, Miss. Kornelia Theodosia</td>\n",
       "      <td>female</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13502</td>\n",
       "      <td>77.9583</td>\n",
       "      <td>D7</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Drazenoic, Mr. Jozef</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349241</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>852</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Svensson, Mr. Johan</td>\n",
       "      <td>male</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>347060</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>212</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Cameron, Miss. Clear Annie</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F.C.C. 13528</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                               Name     Sex  \\\n",
       "32            33         1       3           Glynn, Miss. Mary Agatha  female   \n",
       "275          276         1       1  Andrews, Miss. Kornelia Theodosia  female   \n",
       "130          131         0       3               Drazenoic, Mr. Jozef    male   \n",
       "851          852         0       3                Svensson, Mr. Johan    male   \n",
       "211          212         1       2         Cameron, Miss. Clear Annie  female   \n",
       "\n",
       "      Age  SibSp  Parch        Ticket     Fare Cabin Embarked  \n",
       "32    NaN      0      0        335677   7.7500   NaN        Q  \n",
       "275  63.0      1      0         13502  77.9583    D7        S  \n",
       "130  33.0      0      0        349241   7.8958   NaN        C  \n",
       "851  74.0      0      0        347060   7.7750   NaN        S  \n",
       "211  35.0      0      0  F.C.C. 13528  21.0000   NaN        S  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using sample() will help us see what a dataset line looks like\n",
    "df_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Features: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Numerical Features: \")\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of the early insight analysis, we will take a look at how representative is the training dataset to the actual problem domain. \n",
    "\n",
    "- There are 891 samples in the dataset\n",
    "\n",
    "- Survived is a categorical feature that needs to be treated as categorical, due to the fact that it varies between 0 =\"not survived\" and 1 =\"survived\"\n",
    "\n",
    "  - 38% of the passengers in this sample survived, which is close to the real 32% survival rate of the Titanic \n",
    "\n",
    "- Aboard passengers were quite young: 29 years old, on average. Being 80 years old the oldest one(s)\n",
    "\n",
    "- More than 75% of the passengers did not travel with either spouses or siblings aboard\n",
    "\n",
    "- Although we note there are some potential outliers in e.g. \"age\" and \"fare\" columns, they still seem quite reasonable. For this reason, we will still keep them and wait until we do the statistical EDA to see if we correct them or leave them as they are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Features: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>681</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>347082</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name   Sex  Ticket    Cabin Embarked\n",
       "count                       891   891     891      204      889\n",
       "unique                      891     2     681      147        3\n",
       "top     Braund, Mr. Owen Harris  male  347082  B96 B98        S\n",
       "freq                          1   577       7        4      644"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Categorical Features: \")\n",
    "df_train.describe(include=\"O\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is no name repeated within the dataset\n",
    "\n",
    "- Almost 65% of the passengers were males (577 males/891 total)\n",
    "\n",
    "- Most passengers (ca. 72%) embarked in a port (Embarked=\"S\")\n",
    "\n",
    "- There are multiple duplicated values of \"tickets\" and cabins, meaning that these might be shared among different passengers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values in TRAIN dataset: \n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "______________________________\n",
      "Columns with missing values in TEST dataset: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking missing values \n",
    "print(\"Columns with missing values in TRAIN dataset: \")\n",
    "print(df_train.isnull().sum())\n",
    "print(\"_\"*30)\n",
    "print(\"Columns with missing values in TEST dataset: \")\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some missing values appear in both datasets for columns \"Age\", \"Cabin\", \"Fare\" and \"Embarked\". These values need to be fixed, specially because some algorithms we will use later on do not accept them as inputs. There are two ways to fix them: either delete the entire row where these are located, or replacing them with a reasonable value. Common rule followed is that missing values are populated if possible. However, if most of the values in a column are Null, it could be reasonable to delete that column. If we choose to input a numerical value to a missing one, it's better to use the median as it will affect the least to the final output.\n",
    "\n",
    "Based on above explanation, here are the actions we will take to treat the missing values:\n",
    "\n",
    "- **AGE**: will be populated by the median age. This feature might be closely related to the final survival rate, so it makes sense to try to have it completed\n",
    "\n",
    "- **EMBARKED**: will be populated by the mode. What's more, just 2 missing values out of 891 in the training dataset.\n",
    "\n",
    "- **CABIN**: it will be excluded from the analysis (dropeed) due to the high amount of missing values in both datasets.\n",
    "\n",
    "- **FARE**: we will input the median as well.\n",
    "\n",
    "\n",
    "Even so, there are some columns that we might want to remove from the analysis\n",
    "\n",
    "- **TICKET**: contains lots of duplicated values (22%), which might confuse our model. It seems to be a random number assigned to each passenger and might not have anything to do with the survival rate. PCLASS might have some sort of relationship, though. \n",
    "\n",
    "- **PASSENGERID**: this is the unique identifier for each passenger. Although it identifies which passenger survives or not, it has nothing to do for predicting the final outcome/survival "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=[df_train,df_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values in TRAIN dataset: \n",
      "Survived    0\n",
      "Pclass      0\n",
      "Name        0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "dtype: int64\n",
      "______________________________\n",
      "Columns with missing values in TEST dataset: \n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_p/0_rjv0d5595870_wg4hcb6vm0000gn/T/ipykernel_71989/1816749915.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataset[\"Age\"].fillna(dataset[\"Age\"].median(),inplace=True)\n",
      "/var/folders/_p/0_rjv0d5595870_wg4hcb6vm0000gn/T/ipykernel_71989/1816749915.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataset[\"Fare\"].fillna(dataset[\"Fare\"].median(),inplace=True)\n",
      "/var/folders/_p/0_rjv0d5595870_wg4hcb6vm0000gn/T/ipykernel_71989/1816749915.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataset[\"Embarked\"].fillna(dataset[\"Embarked\"].mode()[0],inplace=True)\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    dataset[\"Age\"].fillna(dataset[\"Age\"].median(),inplace=True)\n",
    "    dataset[\"Fare\"].fillna(dataset[\"Fare\"].median(),inplace=True)\n",
    "    dataset[\"Embarked\"].fillna(dataset[\"Embarked\"].mode()[0],inplace=True)\n",
    "\n",
    "columns_to_drop=[\"Cabin\",\"Ticket\",\"PassengerId\"]\n",
    "df_train.drop(columns=columns_to_drop,axis=1,inplace=True)\n",
    "\n",
    "print(\"Columns with missing values in TRAIN dataset: \")\n",
    "print(df_train.isnull().sum())\n",
    "print(\"_\"*30)\n",
    "print(\"Columns with missing values in TEST dataset: \")\n",
    "print(df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Exploratory and Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have sorted out the missing values, we are going to \"feature engineer\" our data to create extra columns to deal with other passengers' characteristics. When feature engineering, the goal should remain the same, that is identifying which columns (or combination fo columns) affect the most when predicting each passenger's outcome of either surviving or not surviving.\n",
    "\n",
    "We also need to take into account that any change performed in the training dataset (such as adding extra columns), will need to be replicated in the test dataset as well. We must keep consistency within both datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'Name' column, as seen above, consists in a series of words that seem to follow this order: 'surname' + ',' + 'title' + 'Name 1' +...+'Name N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "834            Allum, Mr. Owen George\n",
       "202        Johanson, Mr. Jakob Alfred\n",
       "407    Richards, Master. William Rowe\n",
       "654      Hegarty, Miss. Hanora \"Nora\"\n",
       "776                  Tobin, Mr. Roger\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Name'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the Titles of each value in 'Name' columns\n",
    "#In the form of \" ,Title.\"\n",
    "\n",
    "for dataset in datasets:\n",
    "    #by creating an extra column calles 'Title'\n",
    "    #using regular expression:,\\s* -->looking for comas followed by a space |([^\\.]+) --> looking for any text that is not a point | \n",
    "    # \\. --> looking for the point that 'closes' the title\n",
    "    dataset['Title']=dataset['Name'].str.extract(r',\\s*([^\\.]+)\\.', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title         Sex   \n",
       "Mr            male      517\n",
       "Miss          female    182\n",
       "Mrs           female    125\n",
       "Master        male       40\n",
       "Rev           male        6\n",
       "Dr            male        6\n",
       "Major         male        2\n",
       "Col           male        2\n",
       "Mlle          female      2\n",
       "Sir           male        1\n",
       "Ms            female      1\n",
       "Capt          male        1\n",
       "Mme           female      1\n",
       "Lady          female      1\n",
       "Jonkheer      male        1\n",
       "Dr            female      1\n",
       "Don           male        1\n",
       "the Countess  female      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[['Title','Sex']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classify them in 5 different categories and replace in the column\n",
    "titles=['Mr','Miss','Mrs','Master']\n",
    "\n",
    "#create a function that will return for each row its name titles \n",
    "\n",
    "def transform_title(x):\n",
    "    if x in titles:\n",
    "        return x\n",
    "    else:\n",
    "        return 'Others'\n",
    "\n",
    "for dataset in datasets:\n",
    "    dataset['Title']=dataset['Title'].apply(transform_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title\n",
      "Mr        517\n",
      "Miss      182\n",
      "Mrs       125\n",
      "Master     40\n",
      "Others     27\n",
      "Name: count, dtype: int64\n",
      "Title\n",
      "Mr        240\n",
      "Miss       78\n",
      "Mrs        72\n",
      "Master     21\n",
      "Others      7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As both columns 'SibSp' and 'Parch' indicate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "women=df_train.loc[df_train.Sex=='female']['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7420382165605095"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate_women=sum(women)/len(women)\n",
    "rate_women"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Modelling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Fine-Tuning the Model(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Validation and Final Conclusions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
